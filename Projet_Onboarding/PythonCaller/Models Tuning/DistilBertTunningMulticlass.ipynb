{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9iaS5fYCBDdG"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: transformers in /home/dima/anaconda3/lib/python3.11/site-packages (4.37.2)\n",
            "Requirement already satisfied: filelock in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers) (3.9.0)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers) (2022.7.9)\n",
            "Requirement already satisfied: requests in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers) (0.4.2)\n",
            "Requirement already satisfied: tqdm>=4.27 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (2024.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dima/anaconda3/lib/python3.11/site-packages (from huggingface-hub<1.0,>=0.19.3->transformers) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->transformers) (2024.2.2)\n",
            "Collecting accelerate\n",
            "  Obtaining dependency information for accelerate from https://files.pythonhosted.org/packages/1b/da/24a54b9205fce3bdbaad521c35944d0b0a2d292ac5ae921e484b76312b43/accelerate-0.27.2-py3-none-any.whl.metadata\n",
            "  Downloading accelerate-0.27.2-py3-none-any.whl.metadata (18 kB)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from accelerate) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from accelerate) (23.1)\n",
            "Requirement already satisfied: psutil in /home/dima/anaconda3/lib/python3.11/site-packages (from accelerate) (5.9.0)\n",
            "Requirement already satisfied: pyyaml in /home/dima/anaconda3/lib/python3.11/site-packages (from accelerate) (6.0)\n",
            "Requirement already satisfied: torch>=1.10.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from accelerate) (2.2.0)\n",
            "Requirement already satisfied: huggingface-hub in /home/dima/anaconda3/lib/python3.11/site-packages (from accelerate) (0.20.3)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from accelerate) (0.4.2)\n",
            "Requirement already satisfied: filelock in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (4.9.0)\n",
            "Requirement already satisfied: sympy in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (1.11.1)\n",
            "Requirement already satisfied: networkx in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2024.2.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.10.0->accelerate) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/dima/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.10.0->accelerate) (12.3.101)\n",
            "Requirement already satisfied: requests in /home/dima/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from huggingface-hub->accelerate) (4.65.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.10.0->accelerate) (2.1.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->huggingface-hub->accelerate) (2024.2.2)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/dima/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.10.0->accelerate) (1.3.0)\n",
            "Downloading accelerate-0.27.2-py3-none-any.whl (279 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m280.0/280.0 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: accelerate\n",
            "Successfully installed accelerate-0.27.2\n",
            "Requirement already satisfied: datasets in /home/dima/anaconda3/lib/python3.11/site-packages (2.12.0)\n",
            "Collecting datasets\n",
            "  Obtaining dependency information for datasets from https://files.pythonhosted.org/packages/74/4d/63b033169534f0742b7fe13957118cae08c83b04bfde46511f397872e2e7/datasets-2.17.0-py3-none-any.whl.metadata\n",
            "  Downloading datasets-2.17.0-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: filelock in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (3.9.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (1.24.3)\n",
            "Collecting pyarrow>=12.0.0 (from datasets)\n",
            "  Obtaining dependency information for pyarrow>=12.0.0 from https://files.pythonhosted.org/packages/85/55/636f006d963ddf77270fd294163e149b0719aaaf794de0d023aee88f6335/pyarrow-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata\n",
            "  Downloading pyarrow-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (3.0 kB)\n",
            "Collecting pyarrow-hotfix (from datasets)\n",
            "  Obtaining dependency information for pyarrow-hotfix from https://files.pythonhosted.org/packages/e4/f4/9ec2222f5f5f8ea04f66f184caafd991a39c8782e31f5b0266f101cb68ca/pyarrow_hotfix-0.6-py3-none-any.whl.metadata\n",
            "  Downloading pyarrow_hotfix-0.6-py3-none-any.whl.metadata (3.6 kB)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: multiprocess in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (0.70.14)\n",
            "Collecting fsspec[http]<=2023.10.0,>=2023.1.0 (from datasets)\n",
            "  Obtaining dependency information for fsspec[http]<=2023.10.0,>=2023.1.0 from https://files.pythonhosted.org/packages/e8/f6/3eccfb530aac90ad1301c582da228e4763f19e719ac8200752a4841b0b2d/fsspec-2023.10.0-py3-none-any.whl.metadata\n",
            "  Downloading fsspec-2023.10.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: aiohttp in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (3.8.5)\n",
            "Requirement already satisfied: huggingface-hub>=0.19.4 in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (0.20.3)\n",
            "Requirement already satisfied: packaging in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from datasets) (6.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (2.0.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /home/dima/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/dima/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /home/dima/anaconda3/lib/python3.11/site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /home/dima/anaconda3/lib/python3.11/site-packages (from huggingface-hub>=0.19.4->datasets) (4.9.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests>=2.19.0->datasets) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /home/dima/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from pandas->datasets) (2023.3)\n",
            "Requirement already satisfied: six>=1.5 in /home/dima/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Downloading datasets-2.17.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.6/536.6 kB\u001b[0m \u001b[31m10.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow-15.0.0-cp311-cp311-manylinux_2_28_x86_64.whl (38.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m38.3/38.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pyarrow_hotfix-0.6-py3-none-any.whl (7.9 kB)\n",
            "Downloading fsspec-2023.10.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pyarrow-hotfix, pyarrow, fsspec, datasets\n",
            "  Attempting uninstall: pyarrow\n",
            "    Found existing installation: pyarrow 11.0.0\n",
            "    Uninstalling pyarrow-11.0.0:\n",
            "      Successfully uninstalled pyarrow-11.0.0\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.2.0\n",
            "    Uninstalling fsspec-2024.2.0:\n",
            "      Successfully uninstalled fsspec-2024.2.0\n",
            "  Attempting uninstall: datasets\n",
            "    Found existing installation: datasets 2.12.0\n",
            "    Uninstalling datasets-2.12.0:\n",
            "      Successfully uninstalled datasets-2.12.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-2.17.0 fsspec-2023.10.0 pyarrow-15.0.0 pyarrow-hotfix-0.6\n",
            "Collecting bertviz\n",
            "  Downloading bertviz-1.4.0-py3-none-any.whl (157 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.6/157.6 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: transformers>=2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from bertviz) (4.37.2)\n",
            "Requirement already satisfied: torch>=1.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from bertviz) (2.2.0)\n",
            "Requirement already satisfied: tqdm in /home/dima/anaconda3/lib/python3.11/site-packages (from bertviz) (4.65.0)\n",
            "Collecting boto3 (from bertviz)\n",
            "  Obtaining dependency information for boto3 from https://files.pythonhosted.org/packages/b5/61/beed3c4cefad9038d9ff147cdc38168d5c57b5ec2c697e7a52ff32e0bafa/boto3-1.34.40-py3-none-any.whl.metadata\n",
            "  Downloading boto3-1.34.40-py3-none-any.whl.metadata (6.6 kB)\n",
            "Requirement already satisfied: requests in /home/dima/anaconda3/lib/python3.11/site-packages (from bertviz) (2.31.0)\n",
            "Requirement already satisfied: regex in /home/dima/anaconda3/lib/python3.11/site-packages (from bertviz) (2022.7.9)\n",
            "Collecting sentencepiece (from bertviz)\n",
            "  Downloading sentencepiece-0.1.99-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m28.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (3.9.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (4.9.0)\n",
            "Requirement already satisfied: sympy in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (1.11.1)\n",
            "Requirement already satisfied: networkx in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (3.1)\n",
            "Requirement already satisfied: jinja2 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (2023.10.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from torch>=1.0->bertviz) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /home/dima/anaconda3/lib/python3.11/site-packages (from nvidia-cusolver-cu12==11.4.5.107->torch>=1.0->bertviz) (12.3.101)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.19.3 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers>=2.0->bertviz) (0.20.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers>=2.0->bertviz) (1.24.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers>=2.0->bertviz) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers>=2.0->bertviz) (6.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers>=2.0->bertviz) (0.15.2)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from transformers>=2.0->bertviz) (0.4.2)\n",
            "Collecting botocore<1.35.0,>=1.34.40 (from boto3->bertviz)\n",
            "  Obtaining dependency information for botocore<1.35.0,>=1.34.40 from https://files.pythonhosted.org/packages/4b/ca/f86918789bb290e9fb7573df4d496435c91196440479afc2b803f9d615bd/botocore-1.34.40-py3-none-any.whl.metadata\n",
            "  Downloading botocore-1.34.40-py3-none-any.whl.metadata (5.7 kB)\n",
            "Requirement already satisfied: jmespath<2.0.0,>=0.7.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from boto3->bertviz) (0.10.0)\n",
            "Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->bertviz)\n",
            "  Obtaining dependency information for s3transfer<0.11.0,>=0.10.0 from https://files.pythonhosted.org/packages/12/bb/7e7912e18cd558e7880d9b58ffc57300b2c28ffba9882b3a54ba5ce3ebc4/s3transfer-0.10.0-py3-none-any.whl.metadata\n",
            "  Downloading s3transfer-0.10.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->bertviz) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->bertviz) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->bertviz) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests->bertviz) (2024.2.2)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from botocore<1.35.0,>=1.34.40->boto3->bertviz) (2.8.2)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from jinja2->torch>=1.0->bertviz) (2.1.1)\n",
            "Requirement already satisfied: mpmath>=0.19 in /home/dima/anaconda3/lib/python3.11/site-packages (from sympy->torch>=1.0->bertviz) (1.3.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/dima/anaconda3/lib/python3.11/site-packages (from python-dateutil<3.0.0,>=2.1->botocore<1.35.0,>=1.34.40->boto3->bertviz) (1.16.0)\n",
            "Downloading boto3-1.34.40-py3-none-any.whl (139 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.3/139.3 kB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading botocore-1.34.40-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m49.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading s3transfer-0.10.0-py3-none-any.whl (82 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.1/82.1 kB\u001b[0m \u001b[31m17.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece, botocore, s3transfer, boto3, bertviz\n",
            "  Attempting uninstall: botocore\n",
            "    Found existing installation: botocore 1.29.76\n",
            "    Uninstalling botocore-1.29.76:\n",
            "      Successfully uninstalled botocore-1.29.76\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "aiobotocore 2.5.0 requires botocore<1.29.77,>=1.29.76, but you have botocore 1.34.40 which is incompatible.\n",
            "s3fs 2023.4.0 requires fsspec==2023.4.0, but you have fsspec 2023.10.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed bertviz-1.4.0 boto3-1.34.40 botocore-1.34.40 s3transfer-0.10.0 sentencepiece-0.1.99\n",
            "Collecting umap-learn\n",
            "  Downloading umap-learn-0.5.5.tar.gz (90 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m90.9/90.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.24.3)\n",
            "Requirement already satisfied: scipy>=1.3.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.11.1)\n",
            "Requirement already satisfied: scikit-learn>=0.22 in /home/dima/anaconda3/lib/python3.11/site-packages (from umap-learn) (1.3.0)\n",
            "Requirement already satisfied: numba>=0.51.2 in /home/dima/anaconda3/lib/python3.11/site-packages (from umap-learn) (0.57.1)\n",
            "Collecting pynndescent>=0.5 (from umap-learn)\n",
            "  Obtaining dependency information for pynndescent>=0.5 from https://files.pythonhosted.org/packages/4e/82/0b9851a2fd4da9b57d7931446f5ebab92a98f1f35d3dc0dae5f9ed50a462/pynndescent-0.5.11-py3-none-any.whl.metadata\n",
            "  Downloading pynndescent-0.5.11-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: tqdm in /home/dima/anaconda3/lib/python3.11/site-packages (from umap-learn) (4.65.0)\n",
            "Requirement already satisfied: llvmlite<0.41,>=0.40.0dev0 in /home/dima/anaconda3/lib/python3.11/site-packages (from numba>=0.51.2->umap-learn) (0.40.0)\n",
            "Requirement already satisfied: joblib>=0.11 in /home/dima/anaconda3/lib/python3.11/site-packages (from pynndescent>=0.5->umap-learn) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from scikit-learn>=0.22->umap-learn) (2.2.0)\n",
            "Downloading pynndescent-0.5.11-py3-none-any.whl (55 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m55.8/55.8 kB\u001b[0m \u001b[31m9.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: umap-learn\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for umap-learn: filename=umap_learn-0.5.5-py3-none-any.whl size=86837 sha256=4d0022470f9727e89b2160696bad90f8b21b7d2752355348a7b3016f051acf95\n",
            "  Stored in directory: /home/dima/.cache/pip/wheels/de/07/2e/814a6ee82e37528f2044a609a431028375b149bc31f03c0e27\n",
            "Successfully built umap-learn\n",
            "Installing collected packages: pynndescent, umap-learn\n",
            "Successfully installed pynndescent-0.5.11 umap-learn-0.5.5\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install -U transformers\n",
        "!pip install -U accelerate\n",
        "!pip install -U datasets\n",
        "!pip install -U bertviz\n",
        "!pip install -U umap-learn\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "ZVpzeuGoCubc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting spacy\n",
            "  Obtaining dependency information for spacy from https://files.pythonhosted.org/packages/21/8f/e67f493b6ae4d359d88fb7e22937749b9b40e2cbed601a2f870d2c94159b/spacy-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading spacy-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (25 kB)\n",
            "Collecting spacy-legacy<3.1.0,>=3.0.11 (from spacy)\n",
            "  Downloading spacy_legacy-3.0.12-py2.py3-none-any.whl (29 kB)\n",
            "Collecting spacy-loggers<2.0.0,>=1.0.0 (from spacy)\n",
            "  Obtaining dependency information for spacy-loggers<2.0.0,>=1.0.0 from https://files.pythonhosted.org/packages/33/78/d1a1a026ef3af911159398c939b1509d5c36fe524c7b644f34a5146c4e16/spacy_loggers-1.0.5-py3-none-any.whl.metadata\n",
            "  Downloading spacy_loggers-1.0.5-py3-none-any.whl.metadata (23 kB)\n",
            "Collecting murmurhash<1.1.0,>=0.28.0 (from spacy)\n",
            "  Obtaining dependency information for murmurhash<1.1.0,>=0.28.0 from https://files.pythonhosted.org/packages/93/1b/d880be7ac028cab6bf980acf005c16c0ff381f0c0ba1fd60c284626df3fd/murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.0 kB)\n",
            "Collecting cymem<2.1.0,>=2.0.2 (from spacy)\n",
            "  Obtaining dependency information for cymem<2.1.0,>=2.0.2 from https://files.pythonhosted.org/packages/e5/bc/761acaf88b1fa69a6b75b55c24fbd8b47dab1a3c414d9512e907a646a048/cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (8.4 kB)\n",
            "Collecting preshed<3.1.0,>=3.0.2 (from spacy)\n",
            "  Obtaining dependency information for preshed<3.1.0,>=3.0.2 from https://files.pythonhosted.org/packages/db/69/d9ab108dc670b5be9e292bbd555f39e6eb0a4baab25cd28f792850d5e65b/preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.2 kB)\n",
            "Collecting thinc<8.3.0,>=8.1.8 (from spacy)\n",
            "  Obtaining dependency information for thinc<8.3.0,>=8.1.8 from https://files.pythonhosted.org/packages/78/c1/720e91ab46b4bf95d28f2e7c7e1f4c222a8340c4f88ebb21cd961a34d37a/thinc-8.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading thinc-8.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (15 kB)\n",
            "Collecting wasabi<1.2.0,>=0.9.1 (from spacy)\n",
            "  Obtaining dependency information for wasabi<1.2.0,>=0.9.1 from https://files.pythonhosted.org/packages/8f/69/26cbf0bad11703241cb84d5324d868097f7a8faf2f1888354dac8883f3fc/wasabi-1.1.2-py3-none-any.whl.metadata\n",
            "  Downloading wasabi-1.1.2-py3-none-any.whl.metadata (28 kB)\n",
            "Collecting srsly<3.0.0,>=2.4.3 (from spacy)\n",
            "  Obtaining dependency information for srsly<3.0.0,>=2.4.3 from https://files.pythonhosted.org/packages/e2/a0/153375ade1ca9d33543da7d512329ea9a7d40dc0e0832599f4228b9d761b/srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (20 kB)\n",
            "Collecting catalogue<2.1.0,>=2.0.6 (from spacy)\n",
            "  Obtaining dependency information for catalogue<2.1.0,>=2.0.6 from https://files.pythonhosted.org/packages/9e/96/d32b941a501ab566a16358d68b6eb4e4acc373fab3c3c4d7d9e649f7b4bb/catalogue-2.0.10-py3-none-any.whl.metadata\n",
            "  Downloading catalogue-2.0.10-py3-none-any.whl.metadata (14 kB)\n",
            "Collecting weasel<0.4.0,>=0.1.0 (from spacy)\n",
            "  Obtaining dependency information for weasel<0.4.0,>=0.1.0 from https://files.pythonhosted.org/packages/d5/e5/b63b8e255d89ba4155972990d42523251d4d1368c4906c646597f63870e2/weasel-0.3.4-py3-none-any.whl.metadata\n",
            "  Downloading weasel-0.3.4-py3-none-any.whl.metadata (4.7 kB)\n",
            "Collecting typer<0.10.0,>=0.3.0 (from spacy)\n",
            "  Downloading typer-0.9.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.9/45.9 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy) (5.2.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy) (1.10.8)\n",
            "Requirement already satisfied: jinja2 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy) (68.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy) (23.1)\n",
            "Collecting langcodes<4.0.0,>=3.2.0 (from spacy)\n",
            "  Downloading langcodes-3.3.0-py3-none-any.whl (181 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m181.6/181.6 kB\u001b[0m \u001b[31m11.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.19.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy) (2024.2.2)\n",
            "Collecting blis<0.8.0,>=0.7.8 (from thinc<8.3.0,>=8.1.8->spacy)\n",
            "  Obtaining dependency information for blis<0.8.0,>=0.7.8 from https://files.pythonhosted.org/packages/dc/23/eb01450dc284a7ea8ebc0e5296f1f8fdbe5299169f4c318f836b4284a119/blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata\n",
            "  Downloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.4 kB)\n",
            "Collecting confection<1.0.0,>=0.0.1 (from thinc<8.3.0,>=8.1.8->spacy)\n",
            "  Obtaining dependency information for confection<1.0.0,>=0.0.1 from https://files.pythonhosted.org/packages/39/78/f9d18da7b979a2e6007bfcea2f3c8cc02ed210538ae1ce7e69092aed7b18/confection-0.1.4-py3-none-any.whl.metadata\n",
            "  Downloading confection-0.1.4-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy) (8.0.4)\n",
            "Collecting cloudpathlib<0.17.0,>=0.7.0 (from weasel<0.4.0,>=0.1.0->spacy)\n",
            "  Obtaining dependency information for cloudpathlib<0.17.0,>=0.7.0 from https://files.pythonhosted.org/packages/0f/6e/45b57a7d4573d85d0b0a39d99673dc1f5eea9d92a1a4603b35e968fbf89a/cloudpathlib-0.16.0-py3-none-any.whl.metadata\n",
            "  Downloading cloudpathlib-0.16.0-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from jinja2->spacy) (2.1.1)\n",
            "Downloading spacy-3.7.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.6/6.6 MB\u001b[0m \u001b[31m47.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading catalogue-2.0.10-py3-none-any.whl (17 kB)\n",
            "Downloading cymem-2.0.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (46 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.3/46.3 kB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading murmurhash-1.0.10-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (29 kB)\n",
            "Downloading preshed-3.0.9-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (157 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m157.2/157.2 kB\u001b[0m \u001b[31m25.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading spacy_loggers-1.0.5-py3-none-any.whl (22 kB)\n",
            "Downloading srsly-2.4.8-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (490 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m490.9/490.9 kB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading thinc-8.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (920 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m920.1/920.1 kB\u001b[0m \u001b[31m51.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wasabi-1.1.2-py3-none-any.whl (27 kB)\n",
            "Downloading weasel-0.3.4-py3-none-any.whl (50 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.1/50.1 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blis-0.7.11-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (10.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m10.2/10.2 MB\u001b[0m \u001b[31m53.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
            "\u001b[?25hDownloading cloudpathlib-0.16.0-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m45.0/45.0 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading confection-0.1.4-py3-none-any.whl (35 kB)\n",
            "Installing collected packages: cymem, wasabi, typer, spacy-loggers, spacy-legacy, murmurhash, langcodes, cloudpathlib, catalogue, blis, srsly, preshed, confection, weasel, thinc, spacy\n",
            "Successfully installed blis-0.7.11 catalogue-2.0.10 cloudpathlib-0.16.0 confection-0.1.4 cymem-2.0.8 langcodes-3.3.0 murmurhash-1.0.10 preshed-3.0.9 spacy-3.7.2 spacy-legacy-3.0.12 spacy-loggers-1.0.5 srsly-2.4.8 thinc-8.2.3 typer-0.9.0 wasabi-1.1.2 weasel-0.3.4\n",
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m49.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /home/dima/anaconda3/lib/python3.11/site-packages (from en-core-web-sm==3.7.1) (3.7.2)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.1.8 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.0)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (5.2.1)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.65.0)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.10.8)\n",
            "Requirement already satisfied: jinja2 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.2)\n",
            "Requirement already satisfied: setuptools in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (68.0.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (23.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.24.3)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/dima/anaconda3/lib/python3.11/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /home/dima/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from thinc<8.3.0,>=8.1.8->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.0.4)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.1)\n",
            "Installing collected packages: en-core-web-sm\n",
            "Successfully installed en-core-web-sm-3.7.1\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "Requirement already satisfied: beautifulsoup4 in /home/dima/anaconda3/lib/python3.11/site-packages (4.12.2)\n",
            "Requirement already satisfied: soupsieve>1.2 in /home/dima/anaconda3/lib/python3.11/site-packages (from beautifulsoup4) (2.4)\n",
            "Collecting textblob\n",
            "  Downloading textblob-0.17.1-py2.py3-none-any.whl (636 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m636.8/636.8 kB\u001b[0m \u001b[31m13.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: nltk>=3.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from textblob) (3.8.1)\n",
            "Requirement already satisfied: click in /home/dima/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (8.0.4)\n",
            "Requirement already satisfied: joblib in /home/dima/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (1.2.0)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /home/dima/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (2022.7.9)\n",
            "Requirement already satisfied: tqdm in /home/dima/anaconda3/lib/python3.11/site-packages (from nltk>=3.1->textblob) (4.65.0)\n",
            "Installing collected packages: textblob\n",
            "Successfully installed textblob-0.17.1\n",
            "Collecting mlxtend\n",
            "  Obtaining dependency information for mlxtend from https://files.pythonhosted.org/packages/1c/07/512f6a780239ad6ce06ce2aa7b4067583f5ddcfc7703a964a082c706a070/mlxtend-0.23.1-py3-none-any.whl.metadata\n",
            "  Downloading mlxtend-0.23.1-py3-none-any.whl.metadata (7.3 kB)\n",
            "Requirement already satisfied: scipy>=1.2.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.11.1)\n",
            "Requirement already satisfied: numpy>=1.16.2 in /home/dima/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.24.3)\n",
            "Requirement already satisfied: pandas>=0.24.2 in /home/dima/anaconda3/lib/python3.11/site-packages (from mlxtend) (2.0.3)\n",
            "Requirement already satisfied: scikit-learn>=1.0.2 in /home/dima/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.3.0)\n",
            "Requirement already satisfied: matplotlib>=3.0.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from mlxtend) (3.7.2)\n",
            "Requirement already satisfied: joblib>=0.13.2 in /home/dima/anaconda3/lib/python3.11/site-packages (from mlxtend) (1.2.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.0.5)\n",
            "Requirement already satisfied: cycler>=0.10 in /home/dima/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (4.25.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (10.2.0)\n",
            "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /home/dima/anaconda3/lib/python3.11/site-packages (from matplotlib>=3.0.0->mlxtend) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3.post1)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /home/dima/anaconda3/lib/python3.11/site-packages (from pandas>=0.24.2->mlxtend) (2023.3)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/dima/anaconda3/lib/python3.11/site-packages (from scikit-learn>=1.0.2->mlxtend) (2.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /home/dima/anaconda3/lib/python3.11/site-packages (from python-dateutil>=2.7->matplotlib>=3.0.0->mlxtend) (1.16.0)\n",
            "Downloading mlxtend-0.23.1-py3-none-any.whl (1.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: mlxtend\n",
            "Successfully installed mlxtend-0.23.1\n",
            "Collecting git+https://github.com/laxmimerit/preprocess_kgptalkie.git\n",
            "  Cloning https://github.com/laxmimerit/preprocess_kgptalkie.git to /tmp/pip-req-build-mdrqaj93\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/laxmimerit/preprocess_kgptalkie.git /tmp/pip-req-build-mdrqaj93\n",
            "  Resolved https://github.com/laxmimerit/preprocess_kgptalkie.git to commit 96bf02872d9756f29d6cddb8aafaedcd2a39bbb4\n",
            "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25hBuilding wheels for collected packages: preprocess-kgptalkie\n",
            "  Building wheel for preprocess-kgptalkie (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for preprocess-kgptalkie: filename=preprocess_kgptalkie-0.1.3-py3-none-any.whl size=7603 sha256=aa38f638e8131d73a488ca8a035c97fdb3b3ce35587366f990119c9ebfad7351\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-h7uqm1ek/wheels/74/fe/05/0d013c54ae5e4afb77c6c480378063827c84f57ea5f554e072\n",
            "Successfully built preprocess-kgptalkie\n",
            "Installing collected packages: preprocess-kgptalkie\n",
            "Successfully installed preprocess-kgptalkie-0.1.3\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install spacy\n",
        "!python -m spacy download en_core_web_sm\n",
        "!pip install beautifulsoup4\n",
        "!pip install textblob\n",
        "!pip install mlxtend\n",
        "!pip install git+https://github.com/laxmimerit/preprocess_kgptalkie.git --upgrade --force-reinstall\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cupXo2vlDACq"
      },
      "source": [
        "## Analysiss with pipeline\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 216,
          "referenced_widgets": [
            "19e0cc7f1d85446093613ee4e2f82cc3",
            "cf2ec9bb19bc4ab0a8d4dfb2396e8ed5",
            "8e186a7a490e48029244c6fd0e850950",
            "2c22840546994873a453d1ea61c70488",
            "19074629c3a74dd5a96e54ad34c29a08",
            "7925def7b48d4da190821bd4bc5ddf4d",
            "c39f1cc658ce4d458cdae3d415fbf6b0",
            "8d47ea0898cc4994952e62c716c73124",
            "dd75e00a6a8643ee9a01a6f32b9b9311",
            "cb45bd6e22d34a9a8849b0265979ac4c",
            "d89f5947208e41bca6f4ac6227e6cb9b",
            "e6daf0f3ebfd4ac5945880789e2ebf48",
            "0c20f1c862374fd092e56a4d6df89dd2",
            "e28d9c55317f427f92f183b8ca3453f3",
            "d6be91ce292c4fc89c63757a419c7d8a",
            "7cd297024858429cadb39cc02030d1e9",
            "f99f5642fa5548a88cccbfd095f4a84c",
            "f1ef86387061478dbc0ac23a94fa475a",
            "522c2eca47df4958b0dd48ffdec348bc",
            "30802d99f748481483e3b87faf461c23",
            "6791af96d6dd4c1da80a4c47ccd2fab8",
            "a6d788a081994d7fb0c0edee85b5a46a",
            "d89a0a42fcb54da9a04e128c46240afa",
            "eaf24cff98ff4fb4884a2f6b5989c90a",
            "5c68b998bb914ec0a0d85ecf1255a583",
            "0c5952ec4d9a4a14957f7182ced5384a",
            "20ac61465cbd452094b3c81849f7cb87",
            "600e9429886e4859ac8515ab7ceb33ea",
            "10f2bc546c954d4da572ad030290048f",
            "2f3017dffe134c2db1eae93257060c2c",
            "318fed27e57b4959b462dde312bafccf",
            "36dc7a2e3abb4c998744b73720ed235d",
            "f127965020b143a9a10865876ecd1fe8",
            "1ad5b085f032459491df923700bb66b3",
            "0e809c2b5dcc4f6ebfae493e99065c29",
            "8e16e823753f497291df4b0ce6af2440",
            "faff03ffdb554af8b896a5f11770d3a3",
            "b6e47187ae77423aba7c051c39e4bde8",
            "88f73ce16f5b40e69343da99f363b8e6",
            "0b2e5f66187b4fc4b61b1a2f2e30843c",
            "35452d8b33374a8e95e06d7429f56d55",
            "38f53b9d7bbc4c99845373e8a72460d0",
            "4f948ce2c1a34661ade182b8c151c688",
            "8572dc76b29842b8ac5e376cf2edcf0e"
          ]
        },
        "id": "mMnL0eBEDC1Z",
        "outputId": "df3b0104-a19c-449f-d45b-14638f1772b0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "2024-02-14 09:47:50.785920: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-02-14 09:47:50.785965: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-02-14 09:47:50.787135: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "2024-02-14 09:47:50.793079: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2024-02-14 09:47:51.669539: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "No model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\n",
            "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[{'label': 'POSITIVE', 'score': 0.9998656511306763},\n",
              " {'label': 'NEGATIVE', 'score': 0.9991129040718079}]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "sentiment_pipeline = pipeline(\"sentiment-analysis\")\n",
        "\n",
        "data=['i love you', 'i hate you']\n",
        "\n",
        "sentiment_pipeline(data)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NPnTfXQkDYwn"
      },
      "source": [
        "##  Data Loading and PreProcesing\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "S_Fz5flcDb9z",
        "outputId": "64b0fe12-840e-4d79-c2e0-4a99774b38d8"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>review</th>\n",
              "      <th>sentiment</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>29363</th>\n",
              "      <td>After watch this movie I was surprised that so...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1141</th>\n",
              "      <td>This show has to be my favorite out of all the...</td>\n",
              "      <td>positive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28538</th>\n",
              "      <td>Let me tell you something...this movie exceeds...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30979</th>\n",
              "      <td>Andy Lau stars in another cop undercover tale....</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2195</th>\n",
              "      <td>First of all, let me say the I am LDS or rathe...</td>\n",
              "      <td>negative</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                  review sentiment\n",
              "29363  After watch this movie I was surprised that so...  negative\n",
              "1141   This show has to be my favorite out of all the...  positive\n",
              "28538  Let me tell you something...this movie exceeds...  negative\n",
              "30979  Andy Lau stars in another cop undercover tale....  negative\n",
              "2195   First of all, let me say the I am LDS or rathe...  negative"
            ]
          },
          "execution_count": 2,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import preprocess_kgptalkie as ps\n",
        "df = pd.read_csv(\"https://raw.githubusercontent.com/laxmimerit/All-CSV-ML-Data-Files-Download/master/IMDB-Dataset.csv\")\n",
        "df = df.sample(5_000)\n",
        "df.head()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "brxk-TXZDnVH",
        "outputId": "68877055-3ab6-4226-a7ad-69ebd5b76118"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "review       0\n",
              "sentiment    0\n",
              "dtype: int64"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "df.isnull().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8l8qV54EKtB"
      },
      "source": [
        "## preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "EWowRUlvEL72"
      },
      "outputs": [],
      "source": [
        "df['word_count'] = df['review'].apply(lambda x : len(x.split()))\n",
        "df['char_counts']= df['review'].apply(lambda x: len(x))\n",
        "df['avg_wordlength'] = df['review'].apply(lambda x : ps.get_avg_wordlength(x))\n",
        "df['stopwords_counts'] = df['review'].apply(lambda x : ps.get_stopwords_counts(x))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iNyVt63uFbye",
        "outputId": "e40d883b-6793-4802-fad8-7c5c5cd5152e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/home/dima/anaconda3/lib/python3.11/site-packages/preprocess_kgptalkie/utils.py:97: MarkupResemblesLocatorWarning: The input looks more like a filename than markup. You may want to open this file and pass the filehandle into Beautiful Soup.\n",
            "  return BeautifulSoup(x, 'lxml').get_text().strip()\n"
          ]
        }
      ],
      "source": [
        "df.head()\n",
        "\n",
        "df['review'] = df['review'].str.lower()\n",
        "df['reviex']=df['review'].apply(lambda x : ps.remove_html_tags(x))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 448
        },
        "id": "u1uTyjoZF_Of",
        "outputId": "d218f84e-a16e-4615-e74f-278e2a1785d5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<Axes: >"
            ]
          },
          "execution_count": 6,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "df['word_count'].value_counts().hist(bins=50)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "okWkYPJAGegC"
      },
      "source": [
        "## data Preparation for ML"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ftBaWzNDGY2A"
      },
      "outputs": [],
      "source": [
        "#custom dataset -> Evaluation/ compute metrics -> traingin arguments -> trainer -> training -> testing\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "\n",
        "class CustomDataSet(Dataset):\n",
        "  def __init__(self, texts , labels , tokenizer, max_len=512):\n",
        "    self.texts = texts\n",
        "    self.labels =labels\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.texts)\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    text= str(self.texts[idx])\n",
        "    label = torch.tensor(self.labels[idx])\n",
        "\n",
        "    encoding = self.tokenizer(text, truncation = True , padding = \"max_length\", max_length = self.max_len)\n",
        "\n",
        "    return {\n",
        "        \"input_ids\": encoding['input_ids'],\n",
        "        \"attention_mask\":encoding['attention_mask'],\n",
        "        'labels':label\n",
        "    }\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B_e7tZ0RI_u8",
        "outputId": "18915678-e78e-4af5-ddf6-239c5d24299a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of CamembertForSequenceClassification were not initialized from the model checkpoint at camembert-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "#prepare toeknzier and model\n",
        "from transformers import AutoModelForSequenceClassification, AutoTokenizer\n",
        "\n",
        "import torch\n",
        "\n",
        "checkpoint = 'camembert-base'\n",
        "\n",
        "\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "0bvwFRLMK3jT"
      },
      "outputs": [],
      "source": [
        "X = df['review'].tolist()\n",
        "\n",
        "label2id={'positive' : 1 ,'negative':0}\n",
        "\n",
        "id2label = {1:'positive' , 0: 'negative'}\n",
        "\n",
        "y= df['sentiment'].map(label2id).tolist()\n",
        "\n",
        "\n",
        "dataset = CustomDataSet(X, y ,tokenizer)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cm3_iYzGL61p",
        "outputId": "dce199af-b308-4260-eb0f-4345114f78a3"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "dict_keys(['input_ids', 'attention_mask', 'labels'])"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "dataset[0].keys()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "S8HmEcouL_yU"
      },
      "outputs": [],
      "source": [
        "train_dataset, test_dataset  = train_test_split(dataset  , test_size = 0.2 , random_state = 42)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "def preprocess_logits_for_metrics(logits, labels):\n",
        "    \"\"\"\n",
        "    Original Trainer may have a memory leak. \n",
        "    This is a workaround to avoid storing too many tensors that are not needed.\n",
        "    \"\"\"\n",
        "    pred_ids = torch.argmax(logits, dim=-1)\n",
        "    return pred_ids, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "t5CjRajwNZ9K"
      },
      "outputs": [],
      "source": [
        "## compute metrics\n",
        "\n",
        "from sklearn.metrics import accuracy_score , f1_score\n",
        "\n",
        "def compute_metrics(example):\n",
        "    labels = example.label_ids\n",
        "    preds = example.predictions[0]\n",
        "\n",
        "    f1 = f1_score(labels, preds, average= \"weighted\")\n",
        "    acc= accuracy_score(labels, preds)\n",
        "\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1':f1\n",
        "        }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "3CRwMM5YOH3P"
      },
      "outputs": [],
      "source": [
        "from transformers import TrainingArguments\n",
        "\n",
        "batch_size = 16\n",
        "model_name = 'distilbert_finetune_sentiment'\n",
        "\n",
        "args = TrainingArguments(\n",
        "    do_train=True,\n",
        "    do_eval=True,\n",
        "    output_dir = \"output\",\n",
        "    evaluation_strategy=\"steps\",\n",
        "    eval_steps = 100,   \n",
        "    num_train_epochs=1,\n",
        "    per_device_train_batch_size=32,\n",
        "    per_device_eval_batch_size=32,\n",
        "    gradient_accumulation_steps=2,\n",
        "    eval_accumulation_steps=1,\n",
        "    \n",
        "\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "DB1RHDw8O4oO"
      },
      "outputs": [],
      "source": [
        "from transformers import Trainer \n",
        "\n",
        "trainer = Trainer( model = model,\n",
        "                   args = args ,\n",
        "                   train_dataset = train_dataset,\n",
        "                   eval_dataset= test_dataset,\n",
        "                   compute_metrics = compute_metrics,\n",
        "                   tokenizer = tokenizer,\n",
        "                   preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
        "                   \n",
        "                   )\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "trainer = 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "tO6Bk4ZaPL6r",
        "outputId": "f8033f49-f7c8-438f-a403-0efbb7b192c7"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "037cf9a052234c92b48ae14b17b7cb30",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/250 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 7.79 GiB of which 16.88 MiB is free. Including non-PyTorch memory, this process has 7.71 GiB memory in use. Of the allocated memory 7.51 GiB is allocated by PyTorch, and 39.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[24], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m trainer\u001b[38;5;241m.\u001b[39mtrain()\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1539\u001b[0m, in \u001b[0;36mTrainer.train\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1537\u001b[0m         hf_hub_utils\u001b[38;5;241m.\u001b[39menable_progress_bars()\n\u001b[1;32m   1538\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1539\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m inner_training_loop(\n\u001b[1;32m   1540\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[1;32m   1541\u001b[0m         resume_from_checkpoint\u001b[38;5;241m=\u001b[39mresume_from_checkpoint,\n\u001b[1;32m   1542\u001b[0m         trial\u001b[38;5;241m=\u001b[39mtrial,\n\u001b[1;32m   1543\u001b[0m         ignore_keys_for_eval\u001b[38;5;241m=\u001b[39mignore_keys_for_eval,\n\u001b[1;32m   1544\u001b[0m     )\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:1869\u001b[0m, in \u001b[0;36mTrainer._inner_training_loop\u001b[0;34m(self, batch_size, args, resume_from_checkpoint, trial, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1866\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcallback_handler\u001b[38;5;241m.\u001b[39mon_step_begin(args, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrol)\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maccelerator\u001b[38;5;241m.\u001b[39maccumulate(model):\n\u001b[0;32m-> 1869\u001b[0m     tr_loss_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining_step(model, inputs)\n\u001b[1;32m   1871\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m   1872\u001b[0m     args\u001b[38;5;241m.\u001b[39mlogging_nan_inf_filter\n\u001b[1;32m   1873\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_tpu_available()\n\u001b[1;32m   1874\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m (torch\u001b[38;5;241m.\u001b[39misnan(tr_loss_step) \u001b[38;5;129;01mor\u001b[39;00m torch\u001b[38;5;241m.\u001b[39misinf(tr_loss_step))\n\u001b[1;32m   1875\u001b[0m ):\n\u001b[1;32m   1876\u001b[0m     \u001b[38;5;66;03m# if loss is nan or inf simply add the average of previous logged losses\u001b[39;00m\n\u001b[1;32m   1877\u001b[0m     tr_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m tr_loss \u001b[38;5;241m/\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mglobal_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_globalstep_last_logged)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2772\u001b[0m, in \u001b[0;36mTrainer.training_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   2769\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss_mb\u001b[38;5;241m.\u001b[39mreduce_mean()\u001b[38;5;241m.\u001b[39mdetach()\u001b[38;5;241m.\u001b[39mto(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[1;32m   2771\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss_context_manager():\n\u001b[0;32m-> 2772\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompute_loss(model, inputs)\n\u001b[1;32m   2774\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mn_gpu \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m   2775\u001b[0m     loss \u001b[38;5;241m=\u001b[39m loss\u001b[38;5;241m.\u001b[39mmean()  \u001b[38;5;66;03m# mean() to average on multi-gpu parallel training\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/trainer.py:2795\u001b[0m, in \u001b[0;36mTrainer.compute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m   2793\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2794\u001b[0m     labels \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 2795\u001b[0m outputs \u001b[38;5;241m=\u001b[39m model(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minputs)\n\u001b[1;32m   2796\u001b[0m \u001b[38;5;66;03m# Save past state if it exists\u001b[39;00m\n\u001b[1;32m   2797\u001b[0m \u001b[38;5;66;03m# TODO: this needs to be fixed and made cleaner later.\u001b[39;00m\n\u001b[1;32m   2798\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs\u001b[38;5;241m.\u001b[39mpast_index \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/camembert/modeling_camembert.py:1063\u001b[0m, in \u001b[0;36mCamembertForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, labels, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1055\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1056\u001b[0m \u001b[38;5;124;03mlabels (`torch.LongTensor` of shape `(batch_size,)`, *optional*):\u001b[39;00m\n\u001b[1;32m   1057\u001b[0m \u001b[38;5;124;03m    Labels for computing the sequence classification/regression loss. Indices should be in `[0, ...,\u001b[39;00m\n\u001b[1;32m   1058\u001b[0m \u001b[38;5;124;03m    config.num_labels - 1]`. If `config.num_labels == 1` a regression loss is computed (Mean-Square loss), If\u001b[39;00m\n\u001b[1;32m   1059\u001b[0m \u001b[38;5;124;03m    `config.num_labels > 1` a classification loss is computed (Cross-Entropy).\u001b[39;00m\n\u001b[1;32m   1060\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1061\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[0;32m-> 1063\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mroberta(\n\u001b[1;32m   1064\u001b[0m     input_ids,\n\u001b[1;32m   1065\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mattention_mask,\n\u001b[1;32m   1066\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m   1067\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m   1068\u001b[0m     head_mask\u001b[38;5;241m=\u001b[39mhead_mask,\n\u001b[1;32m   1069\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m   1070\u001b[0m     output_attentions\u001b[38;5;241m=\u001b[39moutput_attentions,\n\u001b[1;32m   1071\u001b[0m     output_hidden_states\u001b[38;5;241m=\u001b[39moutput_hidden_states,\n\u001b[1;32m   1072\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m   1073\u001b[0m )\n\u001b[1;32m   1074\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m   1075\u001b[0m logits \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier(sequence_output)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/camembert/modeling_camembert.py:881\u001b[0m, in \u001b[0;36mCamembertModel.forward\u001b[0;34m(self, input_ids, attention_mask, token_type_ids, position_ids, head_mask, inputs_embeds, encoder_hidden_states, encoder_attention_mask, past_key_values, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    874\u001b[0m \u001b[38;5;66;03m# Prepare head mask if needed\u001b[39;00m\n\u001b[1;32m    875\u001b[0m \u001b[38;5;66;03m# 1.0 in head_mask indicate we keep the head\u001b[39;00m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# attention_probs has shape bsz x n_heads x N x N\u001b[39;00m\n\u001b[1;32m    877\u001b[0m \u001b[38;5;66;03m# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads]\u001b[39;00m\n\u001b[1;32m    878\u001b[0m \u001b[38;5;66;03m# and head_mask is converted to shape [num_hidden_layers x batch x num_heads x seq_length x seq_length]\u001b[39;00m\n\u001b[1;32m    879\u001b[0m head_mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_head_mask(head_mask, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mnum_hidden_layers)\n\u001b[0;32m--> 881\u001b[0m embedding_output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membeddings(\n\u001b[1;32m    882\u001b[0m     input_ids\u001b[38;5;241m=\u001b[39minput_ids,\n\u001b[1;32m    883\u001b[0m     position_ids\u001b[38;5;241m=\u001b[39mposition_ids,\n\u001b[1;32m    884\u001b[0m     token_type_ids\u001b[38;5;241m=\u001b[39mtoken_type_ids,\n\u001b[1;32m    885\u001b[0m     inputs_embeds\u001b[38;5;241m=\u001b[39minputs_embeds,\n\u001b[1;32m    886\u001b[0m     past_key_values_length\u001b[38;5;241m=\u001b[39mpast_key_values_length,\n\u001b[1;32m    887\u001b[0m )\n\u001b[1;32m    888\u001b[0m encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoder(\n\u001b[1;32m    889\u001b[0m     embedding_output,\n\u001b[1;32m    890\u001b[0m     attention_mask\u001b[38;5;241m=\u001b[39mextended_attention_mask,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    898\u001b[0m     return_dict\u001b[38;5;241m=\u001b[39mreturn_dict,\n\u001b[1;32m    899\u001b[0m )\n\u001b[1;32m    900\u001b[0m sequence_output \u001b[38;5;241m=\u001b[39m encoder_outputs[\u001b[38;5;241m0\u001b[39m]\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/transformers/models/camembert/modeling_camembert.py:144\u001b[0m, in \u001b[0;36mCamembertEmbeddings.forward\u001b[0;34m(self, input_ids, token_type_ids, position_ids, inputs_embeds, past_key_values_length)\u001b[0m\n\u001b[1;32m    142\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m token_type_embeddings\n\u001b[1;32m    143\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embedding_type \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mabsolute\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 144\u001b[0m     position_embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mposition_embeddings(position_ids)\n\u001b[1;32m    145\u001b[0m     embeddings \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m position_embeddings\n\u001b[1;32m    146\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mLayerNorm(embeddings)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m forward_call(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/modules/sparse.py:163\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    162\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39membedding(\n\u001b[1;32m    164\u001b[0m         \u001b[38;5;28minput\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpadding_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmax_norm,\n\u001b[1;32m    165\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm_type, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mscale_grad_by_freq, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msparse)\n",
            "File \u001b[0;32m~/anaconda3/lib/python3.11/site-packages/torch/nn/functional.py:2237\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2231\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2232\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2233\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2234\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2235\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2236\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39membedding(weight, \u001b[38;5;28minput\u001b[39m, padding_idx, scale_grad_by_freq, sparse)\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 24.00 MiB. GPU 0 has a total capacity of 7.79 GiB of which 16.88 MiB is free. Including non-PyTorch memory, this process has 7.71 GiB memory in use. Of the allocated memory 7.51 GiB is allocated by PyTorch, and 39.64 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ],
      "source": [
        "trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "EFyqjwWWSkdN"
      },
      "outputs": [],
      "source": [
        "trainer.save_model(model_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDeH7gmtSvXA"
      },
      "source": [
        "## Model testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 254
        },
        "id": "3gK0Y8C9SnVX",
        "outputId": "0812ee66-1403-459a-9f25-f85ce7473f76"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "name 'pipeline' is not defined",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-6a0151191376>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" i'm enjoying this day \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mpipe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'text-classification'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mpipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'pipeline' is not defined"
          ]
        }
      ],
      "source": [
        "#with pipeline\n",
        "\n",
        "text = \" i'm enjoying this day \"\n",
        "\n",
        "pipe = pipeline('text-classification', model_name)\n",
        "pipe(text)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xCNqTfYcTE62"
      },
      "outputs": [],
      "source": [
        "# other way\n",
        "\n",
        "\n",
        "\n",
        "def get_prediction(text):\n",
        "  tok  = DistilBertTokenizer.from_pretrained(model_name)\n",
        "  mod = DistilBertSequenceClassification.from_pretrained(model_name)\n",
        "\n",
        "  input_ids = tok.encode(text,return_rtensor='pt')\n",
        "  output= mod(input_ids)\n",
        "\n",
        "  preds = torch.nn.functional.softmax(output.logits, dim =-1)\n",
        "\n",
        "  prob = torch.max(preds).item()*100\n",
        "\n",
        "  idx = torch.argmax(preds).item()\n",
        "  sentiment = id2label[idx]\n",
        "\n",
        "  return {'sentiment': sentiment,\n",
        "          'probability': prob}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nfbwuQZ7UgkT"
      },
      "outputs": [],
      "source": [
        "text = \"i'm enjoying it \"\n",
        "get_prediction(text)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mémoire Totale du GPU: 7.79 GB\n",
            "Mémoire Libre du GPU: 0.02 GB\n",
            "Mémoire Utilisée du GPU: 7.77 GB\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "# Assurez-vous que CUDA est disponible avant de tenter d'accéder aux informations du GPU\n",
        "if torch.cuda.is_available():\n",
        "    # Sélectionnez le GPU par son index, 0 par défaut pour le premier GPU\n",
        "    torch.cuda.set_device(0)\n",
        "\n",
        "    # Obtenir les informations de mémoire du GPU en octets\n",
        "    total_memory = torch.cuda.get_device_properties(0).total_memory\n",
        "    free_memory = torch.cuda.mem_get_info()[0]\n",
        "    used_memory = total_memory - free_memory\n",
        "\n",
        "    # Convertir les octets en gigaoctets pour une meilleure lisibilité\n",
        "    total_memory_gb = total_memory / (1024**3)\n",
        "    free_memory_gb = free_memory / (1024**3)\n",
        "    used_memory_gb = used_memory / (1024**3)\n",
        "\n",
        "    print(f\"Mémoire Totale du GPU: {total_memory_gb:.2f} GB\")\n",
        "    print(f\"Mémoire Libre du GPU: {free_memory_gb:.2f} GB\")\n",
        "    print(f\"Mémoire Utilisée du GPU: {used_memory_gb:.2f} GB\")\n",
        "else:\n",
        "    print(\"CUDA n'est pas disponible. Vérifiez votre installation de PyTorch ou les pilotes de votre GPU.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "'pynvml module not found, please install pynvml'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.5"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0b2e5f66187b4fc4b61b1a2f2e30843c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "0c20f1c862374fd092e56a4d6df89dd2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f99f5642fa5548a88cccbfd095f4a84c",
            "placeholder": "​",
            "style": "IPY_MODEL_f1ef86387061478dbc0ac23a94fa475a",
            "value": "model.safetensors: 100%"
          }
        },
        "0c5952ec4d9a4a14957f7182ced5384a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_36dc7a2e3abb4c998744b73720ed235d",
            "placeholder": "​",
            "style": "IPY_MODEL_f127965020b143a9a10865876ecd1fe8",
            "value": " 48.0/48.0 [00:00&lt;00:00, 2.98kB/s]"
          }
        },
        "0e809c2b5dcc4f6ebfae493e99065c29": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88f73ce16f5b40e69343da99f363b8e6",
            "placeholder": "​",
            "style": "IPY_MODEL_0b2e5f66187b4fc4b61b1a2f2e30843c",
            "value": "vocab.txt: 100%"
          }
        },
        "10f2bc546c954d4da572ad030290048f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "19074629c3a74dd5a96e54ad34c29a08": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "19e0cc7f1d85446093613ee4e2f82cc3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_cf2ec9bb19bc4ab0a8d4dfb2396e8ed5",
              "IPY_MODEL_8e186a7a490e48029244c6fd0e850950",
              "IPY_MODEL_2c22840546994873a453d1ea61c70488"
            ],
            "layout": "IPY_MODEL_19074629c3a74dd5a96e54ad34c29a08"
          }
        },
        "1ad5b085f032459491df923700bb66b3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0e809c2b5dcc4f6ebfae493e99065c29",
              "IPY_MODEL_8e16e823753f497291df4b0ce6af2440",
              "IPY_MODEL_faff03ffdb554af8b896a5f11770d3a3"
            ],
            "layout": "IPY_MODEL_b6e47187ae77423aba7c051c39e4bde8"
          }
        },
        "20ac61465cbd452094b3c81849f7cb87": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c22840546994873a453d1ea61c70488": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_cb45bd6e22d34a9a8849b0265979ac4c",
            "placeholder": "​",
            "style": "IPY_MODEL_d89f5947208e41bca6f4ac6227e6cb9b",
            "value": " 629/629 [00:00&lt;00:00, 27.3kB/s]"
          }
        },
        "2f3017dffe134c2db1eae93257060c2c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "30802d99f748481483e3b87faf461c23": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "318fed27e57b4959b462dde312bafccf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "35452d8b33374a8e95e06d7429f56d55": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "36dc7a2e3abb4c998744b73720ed235d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "38f53b9d7bbc4c99845373e8a72460d0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "4f948ce2c1a34661ade182b8c151c688": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "522c2eca47df4958b0dd48ffdec348bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "5c68b998bb914ec0a0d85ecf1255a583": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_2f3017dffe134c2db1eae93257060c2c",
            "max": 48,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_318fed27e57b4959b462dde312bafccf",
            "value": 48
          }
        },
        "600e9429886e4859ac8515ab7ceb33ea": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6791af96d6dd4c1da80a4c47ccd2fab8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7925def7b48d4da190821bd4bc5ddf4d": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cd297024858429cadb39cc02030d1e9": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8572dc76b29842b8ac5e376cf2edcf0e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88f73ce16f5b40e69343da99f363b8e6": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d47ea0898cc4994952e62c716c73124": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8e16e823753f497291df4b0ce6af2440": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_35452d8b33374a8e95e06d7429f56d55",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_38f53b9d7bbc4c99845373e8a72460d0",
            "value": 231508
          }
        },
        "8e186a7a490e48029244c6fd0e850950": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_8d47ea0898cc4994952e62c716c73124",
            "max": 629,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_dd75e00a6a8643ee9a01a6f32b9b9311",
            "value": 629
          }
        },
        "a6d788a081994d7fb0c0edee85b5a46a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "b6e47187ae77423aba7c051c39e4bde8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c39f1cc658ce4d458cdae3d415fbf6b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "cb45bd6e22d34a9a8849b0265979ac4c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "cf2ec9bb19bc4ab0a8d4dfb2396e8ed5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7925def7b48d4da190821bd4bc5ddf4d",
            "placeholder": "​",
            "style": "IPY_MODEL_c39f1cc658ce4d458cdae3d415fbf6b0",
            "value": "config.json: 100%"
          }
        },
        "d6be91ce292c4fc89c63757a419c7d8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_6791af96d6dd4c1da80a4c47ccd2fab8",
            "placeholder": "​",
            "style": "IPY_MODEL_a6d788a081994d7fb0c0edee85b5a46a",
            "value": " 268M/268M [00:03&lt;00:00, 181MB/s]"
          }
        },
        "d89a0a42fcb54da9a04e128c46240afa": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_eaf24cff98ff4fb4884a2f6b5989c90a",
              "IPY_MODEL_5c68b998bb914ec0a0d85ecf1255a583",
              "IPY_MODEL_0c5952ec4d9a4a14957f7182ced5384a"
            ],
            "layout": "IPY_MODEL_20ac61465cbd452094b3c81849f7cb87"
          }
        },
        "d89f5947208e41bca6f4ac6227e6cb9b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "dd75e00a6a8643ee9a01a6f32b9b9311": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "e28d9c55317f427f92f183b8ca3453f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_522c2eca47df4958b0dd48ffdec348bc",
            "max": 267832558,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_30802d99f748481483e3b87faf461c23",
            "value": 267832558
          }
        },
        "e6daf0f3ebfd4ac5945880789e2ebf48": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_0c20f1c862374fd092e56a4d6df89dd2",
              "IPY_MODEL_e28d9c55317f427f92f183b8ca3453f3",
              "IPY_MODEL_d6be91ce292c4fc89c63757a419c7d8a"
            ],
            "layout": "IPY_MODEL_7cd297024858429cadb39cc02030d1e9"
          }
        },
        "eaf24cff98ff4fb4884a2f6b5989c90a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_600e9429886e4859ac8515ab7ceb33ea",
            "placeholder": "​",
            "style": "IPY_MODEL_10f2bc546c954d4da572ad030290048f",
            "value": "tokenizer_config.json: 100%"
          }
        },
        "f127965020b143a9a10865876ecd1fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f1ef86387061478dbc0ac23a94fa475a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "f99f5642fa5548a88cccbfd095f4a84c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "faff03ffdb554af8b896a5f11770d3a3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4f948ce2c1a34661ade182b8c151c688",
            "placeholder": "​",
            "style": "IPY_MODEL_8572dc76b29842b8ac5e376cf2edcf0e",
            "value": " 232k/232k [00:00&lt;00:00, 3.25MB/s]"
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
